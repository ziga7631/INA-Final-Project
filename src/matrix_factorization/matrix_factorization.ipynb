{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix factorization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import surprise\n",
    "from IPython.display import display\n",
    "from surprise import Reader, Dataset, SVD, NMF\n",
    "from surprise.model_selection import train_test_split, cross_validate\n",
    "\n",
    "from data.data_helper_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/'\n",
    "books_df, users_df, ratings_df = load_data(data_path) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare the data for the surprise library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(ratings_df[['user_id', 'book_id', 'rating']], reader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split the data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = surprise.model_selection.train_test_split(data, test_size=0.2,random_state=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get train test panda datagrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(test, columns=[\"user_id\", \"book_id\", \"rating\"])\n",
    "\n",
    "trainset_to_tuples = [(train.to_raw_uid(uid), train.to_raw_iid(iid), rating) for (uid, iid, rating) in train.all_ratings()]\n",
    "train_df = pd.DataFrame(trainset_to_tuples, columns=[\"user_id\", \"book_id\", \"rating\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train the matrix factorization model using the Singular Value Decomposition (SVD) algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x2bb109f6e90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = surprise.SVD(n_factors=20 , n_epochs=40,  reg_all=0.1)\n",
    "svd.fit(train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.83\n",
      "MAE: 0.65\n"
     ]
    }
   ],
   "source": [
    "# 83, 65\n",
    "predictions = svd.test(test)\n",
    "rmse = surprise.accuracy.rmse(predictions, verbose=False)\n",
    "mae = surprise.accuracy.mae(predictions, verbose=False)\n",
    "\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"MAE: {mae:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Make recommendations for a specific user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_recommendations(user_id, model, n=10):\n",
    "    all_book_ids = set(ratings_df['book_id'].unique())\n",
    "    user_rated_books = set(ratings_df[ratings_df['user_id'] == user_id]['book_id'])\n",
    "\n",
    "    books_not_yet_rated = list(all_book_ids - user_rated_books)\n",
    "    predictions = [model.predict(user_id, book_id) for book_id in books_not_yet_rated]\n",
    "    sorted_predictions = sorted(predictions, key=lambda x: x.est, reverse=True)\n",
    "    \n",
    "    return [(prediction.iid, prediction.est) for prediction in sorted_predictions[:n]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_user_id = 10\n",
    "top_n_recommendations_with_ratings = get_top_n_recommendations(query_user_id, svd, n=20)\n",
    "top_n_recommendations, predicted_ratings = zip(*top_n_recommendations_with_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the top rated books by the user\n",
    "user_book_ratings = ratings_df[ratings_df['user_id'] == query_user_id]\n",
    "user_book_ratings = user_book_ratings.merge(books_df, left_on='book_id', right_index=True, how='inner')\n",
    "user_book_ratings = user_book_ratings[['book_id', 'title', 'authors', 'average_rating', 'rating']].sort_values('rating', ascending=False)\n",
    "print(\"Top rated books by user:\")\n",
    "display(user_book_ratings)\n",
    "\n",
    "# Display the information of the recommended books\n",
    "recommended_books = books_df.loc[list(top_n_recommendations)]\n",
    "recommended_books['predicted_rating'] = predicted_ratings\n",
    "print(\"\\nRecommended books:\")\n",
    "display(recommended_books)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate recommendations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get top n recommendations for each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting recommendations for users: 100%|██████████| 39686/39686 [56:49<00:00, 11.64it/s]  \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def get_top_recommendation_for_user(user_id, all_books, model, n=500):\n",
    "    user_rated_books = set(train_df[train_df['user_id'] == user_id]['book_id'])\n",
    "    books_not_yet_rated = list(all_books - user_rated_books) # Remove only from train!\n",
    "    \n",
    "    predictions = [model.predict(user_id, book_id) for book_id in books_not_yet_rated]\n",
    "    sorted_predictions = sorted(predictions, key=lambda x: x.est, reverse=True)\n",
    "    return [(prediction.iid, prediction.est) for prediction in sorted_predictions[:n]]\n",
    "\n",
    "def get_recommendations_for_all_users(user_ids, model, n=500):\n",
    "    all_book_ids = set(ratings_df['book_id'].unique())\n",
    "    recommendations = {}\n",
    "    for user_id in tqdm(user_ids, desc=\"Getting recommendations for users\"):\n",
    "        top_n_recommendations = get_top_recommendation_for_user(user_id, all_book_ids, model, n=n)\n",
    "        recommendations[user_id] = [book_id for (book_id, _) in top_n_recommendations]\n",
    "    return recommendations\n",
    "\n",
    "user_ids = ratings_df['user_id'].unique()\n",
    "recommendations = get_recommendations_for_all_users(user_ids, svd, n=500)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate precision and recall at K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_at_k(user_id, top_n_recommendations, k= 100):\n",
    "    relevant_items  = set(test_df[(test_df.user_id == user_id) & (test_df.rating>=3)]['book_id'])\n",
    "    if len (relevant_items ) == 0: return -1, -1 # Can not evaluate this user if no relavant items in test set\n",
    "    true_positives = len(relevant_items.intersection(set(top_n_recommendations[:k])))\n",
    "\n",
    "    false_positives = len(top_n_recommendations) - true_positives\n",
    "    false_negatives = len(relevant_items) - true_positives\n",
    "\n",
    "    tp, fp, fn = true_positives, false_positives, false_negatives\n",
    "\n",
    "    precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
    "    recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 100\n",
    "\n",
    "total_precision = 0\n",
    "total_recall = 0\n",
    "count = len(user_ids)\n",
    "\n",
    "for user_id in tqdm(user_ids, desc=\"Evaluating recommendations\"):\n",
    "    top_n_recommendations = recommendations[user_id]\n",
    "    precision, recall = precision_recall_at_k(user_id, top_n_recommendations, k)\n",
    "\n",
    "    if precision > 0:\n",
    "        total_precision += precision\n",
    "        total_recall += recall\n",
    "    elif precision < 0: # There were no relavant items\n",
    "        count -=1\n",
    "\n",
    "average_precision = total_precision / count\n",
    "average_recall = total_recall / count\n",
    "\n",
    "print(f\"Precision@{k}: {average_precision:.5f}\")\n",
    "print(f\"Recall@{k}: {average_recall:.5f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
